{"cells":[{"cell_type":"markdown","metadata":{"id":"ySf0bka5HAwq"},"source":["# HyperParameter Tunning with DNN"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"jzv_SDlHGCjU","executionInfo":{"status":"ok","timestamp":1668051721830,"user_tz":-330,"elapsed":1545,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}},"outputId":"59c22e82-5d85-4495-944d-5d400920b9a8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n","4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62    '0'  \n","1  0.125895 -0.008983  0.014724    2.69    '0'  \n","2 -0.139097 -0.055353 -0.059752  378.66    '0'  \n","3 -0.221929  0.062723  0.061458  123.50    '0'  \n","4  0.502292  0.219422  0.215153   69.99    '0'  \n","\n","[5 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-adf533dc-f86d-49d7-a2ed-28bf041d99eb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>'0'</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>'0'</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>'0'</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>'0'</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>'0'</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adf533dc-f86d-49d7-a2ed-28bf041d99eb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-adf533dc-f86d-49d7-a2ed-28bf041d99eb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-adf533dc-f86d-49d7-a2ed-28bf041d99eb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","df = pd.read_csv(\"/content/fraud.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GA_BasMTHzUo","executionInfo":{"status":"ok","timestamp":1668051862827,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["mapped_class = {\"'0'\": 0, \"'1'\": 1}\n","df['Class'] = df['Class'].map(lambda x: mapped_class[x])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":770},"id":"raH-vPEoG6XG","outputId":"a8a9dd6d-953e-4aae-94a3-f8f424bc1dc2"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-711c48ce-7b21-421a-83c9-ec841acef01b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.0</td>\n","      <td>-0.425966</td>\n","      <td>0.960523</td>\n","      <td>1.141109</td>\n","      <td>-0.168252</td>\n","      <td>0.420987</td>\n","      <td>-0.029728</td>\n","      <td>0.476201</td>\n","      <td>0.260314</td>\n","      <td>-0.568671</td>\n","      <td>...</td>\n","      <td>-0.208254</td>\n","      <td>-0.559825</td>\n","      <td>-0.026398</td>\n","      <td>-0.371427</td>\n","      <td>-0.232794</td>\n","      <td>0.105915</td>\n","      <td>0.253844</td>\n","      <td>0.081080</td>\n","      <td>3.67</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.0</td>\n","      <td>1.229658</td>\n","      <td>0.141004</td>\n","      <td>0.045371</td>\n","      <td>1.202613</td>\n","      <td>0.191881</td>\n","      <td>0.272708</td>\n","      <td>-0.005159</td>\n","      <td>0.081213</td>\n","      <td>0.464960</td>\n","      <td>...</td>\n","      <td>-0.167716</td>\n","      <td>-0.270710</td>\n","      <td>-0.154104</td>\n","      <td>-0.780055</td>\n","      <td>0.750137</td>\n","      <td>-0.257237</td>\n","      <td>0.034507</td>\n","      <td>0.005168</td>\n","      <td>4.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7.0</td>\n","      <td>-0.644269</td>\n","      <td>1.417964</td>\n","      <td>1.074380</td>\n","      <td>-0.492199</td>\n","      <td>0.948934</td>\n","      <td>0.428118</td>\n","      <td>1.120631</td>\n","      <td>-3.807864</td>\n","      <td>0.615375</td>\n","      <td>...</td>\n","      <td>1.943465</td>\n","      <td>-1.015455</td>\n","      <td>0.057504</td>\n","      <td>-0.649709</td>\n","      <td>-0.415267</td>\n","      <td>-0.051634</td>\n","      <td>-1.206921</td>\n","      <td>-1.085339</td>\n","      <td>40.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7.0</td>\n","      <td>-0.894286</td>\n","      <td>0.286157</td>\n","      <td>-0.113192</td>\n","      <td>-0.271526</td>\n","      <td>2.669599</td>\n","      <td>3.721818</td>\n","      <td>0.370145</td>\n","      <td>0.851084</td>\n","      <td>-0.392048</td>\n","      <td>...</td>\n","      <td>-0.073425</td>\n","      <td>-0.268092</td>\n","      <td>-0.204233</td>\n","      <td>1.011592</td>\n","      <td>0.373205</td>\n","      <td>-0.384157</td>\n","      <td>0.011747</td>\n","      <td>0.142404</td>\n","      <td>93.20</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9.0</td>\n","      <td>-0.338262</td>\n","      <td>1.119593</td>\n","      <td>1.044367</td>\n","      <td>-0.222187</td>\n","      <td>0.499361</td>\n","      <td>-0.246761</td>\n","      <td>0.651583</td>\n","      <td>0.069539</td>\n","      <td>-0.736727</td>\n","      <td>...</td>\n","      <td>-0.246914</td>\n","      <td>-0.633753</td>\n","      <td>-0.120794</td>\n","      <td>-0.385050</td>\n","      <td>-0.069733</td>\n","      <td>0.094199</td>\n","      <td>0.246219</td>\n","      <td>0.083076</td>\n","      <td>3.68</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10.0</td>\n","      <td>1.449044</td>\n","      <td>-1.176339</td>\n","      <td>0.913860</td>\n","      <td>-1.375667</td>\n","      <td>-1.971383</td>\n","      <td>-0.629152</td>\n","      <td>-1.423236</td>\n","      <td>0.048456</td>\n","      <td>-1.720408</td>\n","      <td>...</td>\n","      <td>-0.009302</td>\n","      <td>0.313894</td>\n","      <td>0.027740</td>\n","      <td>0.500512</td>\n","      <td>0.251367</td>\n","      <td>-0.129478</td>\n","      <td>0.042850</td>\n","      <td>0.016253</td>\n","      <td>7.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10.0</td>\n","      <td>0.384978</td>\n","      <td>0.616109</td>\n","      <td>-0.874300</td>\n","      <td>-0.094019</td>\n","      <td>2.924584</td>\n","      <td>3.317027</td>\n","      <td>0.470455</td>\n","      <td>0.538247</td>\n","      <td>-0.558895</td>\n","      <td>...</td>\n","      <td>0.049924</td>\n","      <td>0.238422</td>\n","      <td>0.009130</td>\n","      <td>0.996710</td>\n","      <td>-0.767315</td>\n","      <td>-0.492208</td>\n","      <td>0.042472</td>\n","      <td>-0.054337</td>\n","      <td>9.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10.0</td>\n","      <td>1.249999</td>\n","      <td>-1.221637</td>\n","      <td>0.383930</td>\n","      <td>-1.234899</td>\n","      <td>-1.485419</td>\n","      <td>-0.753230</td>\n","      <td>-0.689405</td>\n","      <td>-0.227487</td>\n","      <td>-2.094011</td>\n","      <td>...</td>\n","      <td>-0.231809</td>\n","      <td>-0.483285</td>\n","      <td>0.084668</td>\n","      <td>0.392831</td>\n","      <td>0.161135</td>\n","      <td>-0.354990</td>\n","      <td>0.026416</td>\n","      <td>0.042422</td>\n","      <td>121.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>11.0</td>\n","      <td>1.069374</td>\n","      <td>0.287722</td>\n","      <td>0.828613</td>\n","      <td>2.712520</td>\n","      <td>-0.178398</td>\n","      <td>0.337544</td>\n","      <td>-0.096717</td>\n","      <td>0.115982</td>\n","      <td>-0.221083</td>\n","      <td>...</td>\n","      <td>-0.036876</td>\n","      <td>0.074412</td>\n","      <td>-0.071407</td>\n","      <td>0.104744</td>\n","      <td>0.548265</td>\n","      <td>0.104094</td>\n","      <td>0.021491</td>\n","      <td>0.021293</td>\n","      <td>27.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>12.0</td>\n","      <td>-2.791855</td>\n","      <td>-0.327771</td>\n","      <td>1.641750</td>\n","      <td>1.767473</td>\n","      <td>-0.136588</td>\n","      <td>0.807596</td>\n","      <td>-0.422911</td>\n","      <td>-1.907107</td>\n","      <td>0.755713</td>\n","      <td>...</td>\n","      <td>1.151663</td>\n","      <td>0.222182</td>\n","      <td>1.020586</td>\n","      <td>0.028317</td>\n","      <td>-0.232746</td>\n","      <td>-0.235557</td>\n","      <td>-0.164778</td>\n","      <td>-0.030154</td>\n","      <td>58.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>12.0</td>\n","      <td>-0.752417</td>\n","      <td>0.345485</td>\n","      <td>2.057323</td>\n","      <td>-1.468643</td>\n","      <td>-1.158394</td>\n","      <td>-0.077850</td>\n","      <td>-0.608581</td>\n","      <td>0.003603</td>\n","      <td>-0.436167</td>\n","      <td>...</td>\n","      <td>0.499625</td>\n","      <td>1.353650</td>\n","      <td>-0.256573</td>\n","      <td>-0.065084</td>\n","      <td>-0.039124</td>\n","      <td>-0.087086</td>\n","      <td>-0.180998</td>\n","      <td>0.129394</td>\n","      <td>15.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>12.0</td>\n","      <td>1.103215</td>\n","      <td>-0.040296</td>\n","      <td>1.267332</td>\n","      <td>1.289091</td>\n","      <td>-0.735997</td>\n","      <td>0.288069</td>\n","      <td>-0.586057</td>\n","      <td>0.189380</td>\n","      <td>0.782333</td>\n","      <td>...</td>\n","      <td>-0.024612</td>\n","      <td>0.196002</td>\n","      <td>0.013802</td>\n","      <td>0.103758</td>\n","      <td>0.364298</td>\n","      <td>-0.382261</td>\n","      <td>0.092809</td>\n","      <td>0.037051</td>\n","      <td>12.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>13.0</td>\n","      <td>-0.436905</td>\n","      <td>0.918966</td>\n","      <td>0.924591</td>\n","      <td>-0.727219</td>\n","      <td>0.915679</td>\n","      <td>-0.127867</td>\n","      <td>0.707642</td>\n","      <td>0.087962</td>\n","      <td>-0.665271</td>\n","      <td>...</td>\n","      <td>-0.194796</td>\n","      <td>-0.672638</td>\n","      <td>-0.156858</td>\n","      <td>-0.888386</td>\n","      <td>-0.342413</td>\n","      <td>-0.049027</td>\n","      <td>0.079692</td>\n","      <td>0.131024</td>\n","      <td>0.89</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>14.0</td>\n","      <td>-5.401258</td>\n","      <td>-5.450148</td>\n","      <td>1.186305</td>\n","      <td>1.736239</td>\n","      <td>3.049106</td>\n","      <td>-1.763406</td>\n","      <td>-1.559738</td>\n","      <td>0.160842</td>\n","      <td>1.233090</td>\n","      <td>...</td>\n","      <td>-0.503600</td>\n","      <td>0.984460</td>\n","      <td>2.458589</td>\n","      <td>0.042119</td>\n","      <td>-0.481631</td>\n","      <td>-0.621272</td>\n","      <td>0.392053</td>\n","      <td>0.949594</td>\n","      <td>46.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>15.0</td>\n","      <td>1.492936</td>\n","      <td>-1.029346</td>\n","      <td>0.454795</td>\n","      <td>-1.438026</td>\n","      <td>-1.555434</td>\n","      <td>-0.720961</td>\n","      <td>-1.080664</td>\n","      <td>-0.053127</td>\n","      <td>-1.978682</td>\n","      <td>...</td>\n","      <td>-0.177650</td>\n","      <td>-0.175074</td>\n","      <td>0.040002</td>\n","      <td>0.295814</td>\n","      <td>0.332931</td>\n","      <td>-0.220385</td>\n","      <td>0.022298</td>\n","      <td>0.007602</td>\n","      <td>5.00</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-711c48ce-7b21-421a-83c9-ec841acef01b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-711c48ce-7b21-421a-83c9-ec841acef01b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-711c48ce-7b21-421a-83c9-ec841acef01b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    Time        V1        V2        V3        V4        V5        V6  \\\n","0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n","1    0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n","2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n","3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n","4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n","5    2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n","6    4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n","7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n","8    7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n","9    9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n","10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n","11  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n","12  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n","13  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544   \n","14  12.0 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n","15  12.0 -0.752417  0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n","16  12.0  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069   \n","17  13.0 -0.436905  0.918966  0.924591 -0.727219  0.915679 -0.127867   \n","18  14.0 -5.401258 -5.450148  1.186305  1.736239  3.049106 -1.763406   \n","19  15.0  1.492936 -1.029346  0.454795 -1.438026 -1.555434 -0.720961   \n","\n","          V7        V8        V9  ...       V21       V22       V23       V24  \\\n","0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n","1  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n","2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n","3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n","4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n","5   0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427   \n","6  -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055   \n","7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n","8   0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592   \n","9   0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050   \n","10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n","11  0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710   \n","12 -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831   \n","13 -0.096717  0.115982 -0.221083  ... -0.036876  0.074412 -0.071407  0.104744   \n","14 -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586  0.028317   \n","15 -0.608581  0.003603 -0.436167  ...  0.499625  1.353650 -0.256573 -0.065084   \n","16 -0.586057  0.189380  0.782333  ... -0.024612  0.196002  0.013802  0.103758   \n","17  0.707642  0.087962 -0.665271  ... -0.194796 -0.672638 -0.156858 -0.888386   \n","18 -1.559738  0.160842  1.233090  ... -0.503600  0.984460  2.458589  0.042119   \n","19 -1.080664 -0.053127 -1.978682  ... -0.177650 -0.175074  0.040002  0.295814   \n","\n","         V25       V26       V27       V28  Amount  Class  \n","0   0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n","1   0.167170  0.125895 -0.008983  0.014724    2.69      0  \n","2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n","3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n","4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n","5  -0.232794  0.105915  0.253844  0.081080    3.67      0  \n","6   0.750137 -0.257237  0.034507  0.005168    4.99      0  \n","7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n","8   0.373205 -0.384157  0.011747  0.142404   93.20      0  \n","9  -0.069733  0.094199  0.246219  0.083076    3.68      0  \n","10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n","11 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n","12  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n","13  0.548265  0.104094  0.021491  0.021293   27.50      0  \n","14 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n","15 -0.039124 -0.087086 -0.180998  0.129394   15.99      0  \n","16  0.364298 -0.382261  0.092809  0.037051   12.99      0  \n","17 -0.342413 -0.049027  0.079692  0.131024    0.89      0  \n","18 -0.481631 -0.621272  0.392053  0.949594   46.80      0  \n","19  0.332931 -0.220385  0.022298  0.007602    5.00      0  \n","\n","[20 rows x 31 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head(20)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lIPT4xLwG6bg","executionInfo":{"status":"ok","timestamp":1668052070644,"user_tz":-330,"elapsed":630,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","time_scaler = StandardScaler()\n","amount_scaler = StandardScaler()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZGSvtVboIq9Q","executionInfo":{"status":"ok","timestamp":1668052073704,"user_tz":-330,"elapsed":609,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["# Scaling the time feature\n","scaled_time = time_scaler.fit_transform(df[['Time']])\n","flat_list1 = [item for sublist in scaled_time.tolist() for item in sublist]\n","scaled_time = pd.Series(flat_list1)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8VnH8Xp-Isia","executionInfo":{"status":"ok","timestamp":1668052075945,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["# Scaling the Amount feature\n","scaled_amount = amount_scaler.fit_transform(df[['Amount']])\n","flat_list1 = [item for sublist in scaled_amount.tolist() for item in sublist]\n","scaled_amount = pd.Series(flat_list1)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"P9bBPd_XfC4e","outputId":"0177ebf0-37e2-4fea-b900-52a8aec71bec","executionInfo":{"status":"ok","timestamp":1668052079735,"user_tz":-330,"elapsed":628,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Time        V1        V2        V3        V4        V5        V6  \\\n","192872  129893.0 -1.645597 -0.303721 -0.464308 -0.924785  1.629177 -1.157988   \n","234308  147917.0 -0.537994  0.632445  1.859128  0.855622  0.119784 -0.011361   \n","54387    46425.0  0.603866 -1.499975  0.847550 -0.657394 -1.866565 -0.559688   \n","125075   77525.0 -1.198375  1.000622  1.096542  1.357014  0.063093  0.028698   \n","69176    53301.0 -2.423090  0.002590  1.778551 -1.197764  1.355823 -0.417638   \n","\n","              V7        V8        V9  ...       V23       V24       V25  \\\n","192872  2.416229 -0.364198 -1.204503  ... -0.155526 -0.368822  1.817993   \n","234308  0.540241  0.162789  0.212385  ... -0.062442 -0.114395  0.484837   \n","54387  -0.588899  0.138502  1.713959  ... -0.345244  0.537071  0.269301   \n","125075  0.558409  0.181929 -0.216234  ...  0.160425  0.109228 -0.020617   \n","69176  -1.026683 -0.428347  0.135782  ... -1.017931 -0.167035 -0.136833   \n","\n","             V26       V27       V28  Amount  Class  scaled_amount  \\\n","192872  0.160898 -0.192315  0.029654  268.12      0       0.718737   \n","234308 -0.889939 -0.005962 -0.041456   23.70      0      -0.258475   \n","54387  -0.607835  0.034597  0.081594  302.58      0       0.856512   \n","125075 -0.257692 -0.022162 -0.144941   39.00      0      -0.197304   \n","69176   0.892118  0.553089  0.090010   20.00      0      -0.273268   \n","\n","        scaled_time  \n","192872     0.738694  \n","234308     1.118242  \n","54387     -1.018969  \n","125075    -0.364067  \n","69176     -0.874175  \n","\n","[5 rows x 33 columns]"],"text/html":["\n","  <div id=\"df-726fdddf-04f8-4c06-89e6-21da2160011e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","      <th>scaled_amount</th>\n","      <th>scaled_time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>192872</th>\n","      <td>129893.0</td>\n","      <td>-1.645597</td>\n","      <td>-0.303721</td>\n","      <td>-0.464308</td>\n","      <td>-0.924785</td>\n","      <td>1.629177</td>\n","      <td>-1.157988</td>\n","      <td>2.416229</td>\n","      <td>-0.364198</td>\n","      <td>-1.204503</td>\n","      <td>...</td>\n","      <td>-0.155526</td>\n","      <td>-0.368822</td>\n","      <td>1.817993</td>\n","      <td>0.160898</td>\n","      <td>-0.192315</td>\n","      <td>0.029654</td>\n","      <td>268.12</td>\n","      <td>0</td>\n","      <td>0.718737</td>\n","      <td>0.738694</td>\n","    </tr>\n","    <tr>\n","      <th>234308</th>\n","      <td>147917.0</td>\n","      <td>-0.537994</td>\n","      <td>0.632445</td>\n","      <td>1.859128</td>\n","      <td>0.855622</td>\n","      <td>0.119784</td>\n","      <td>-0.011361</td>\n","      <td>0.540241</td>\n","      <td>0.162789</td>\n","      <td>0.212385</td>\n","      <td>...</td>\n","      <td>-0.062442</td>\n","      <td>-0.114395</td>\n","      <td>0.484837</td>\n","      <td>-0.889939</td>\n","      <td>-0.005962</td>\n","      <td>-0.041456</td>\n","      <td>23.70</td>\n","      <td>0</td>\n","      <td>-0.258475</td>\n","      <td>1.118242</td>\n","    </tr>\n","    <tr>\n","      <th>54387</th>\n","      <td>46425.0</td>\n","      <td>0.603866</td>\n","      <td>-1.499975</td>\n","      <td>0.847550</td>\n","      <td>-0.657394</td>\n","      <td>-1.866565</td>\n","      <td>-0.559688</td>\n","      <td>-0.588899</td>\n","      <td>0.138502</td>\n","      <td>1.713959</td>\n","      <td>...</td>\n","      <td>-0.345244</td>\n","      <td>0.537071</td>\n","      <td>0.269301</td>\n","      <td>-0.607835</td>\n","      <td>0.034597</td>\n","      <td>0.081594</td>\n","      <td>302.58</td>\n","      <td>0</td>\n","      <td>0.856512</td>\n","      <td>-1.018969</td>\n","    </tr>\n","    <tr>\n","      <th>125075</th>\n","      <td>77525.0</td>\n","      <td>-1.198375</td>\n","      <td>1.000622</td>\n","      <td>1.096542</td>\n","      <td>1.357014</td>\n","      <td>0.063093</td>\n","      <td>0.028698</td>\n","      <td>0.558409</td>\n","      <td>0.181929</td>\n","      <td>-0.216234</td>\n","      <td>...</td>\n","      <td>0.160425</td>\n","      <td>0.109228</td>\n","      <td>-0.020617</td>\n","      <td>-0.257692</td>\n","      <td>-0.022162</td>\n","      <td>-0.144941</td>\n","      <td>39.00</td>\n","      <td>0</td>\n","      <td>-0.197304</td>\n","      <td>-0.364067</td>\n","    </tr>\n","    <tr>\n","      <th>69176</th>\n","      <td>53301.0</td>\n","      <td>-2.423090</td>\n","      <td>0.002590</td>\n","      <td>1.778551</td>\n","      <td>-1.197764</td>\n","      <td>1.355823</td>\n","      <td>-0.417638</td>\n","      <td>-1.026683</td>\n","      <td>-0.428347</td>\n","      <td>0.135782</td>\n","      <td>...</td>\n","      <td>-1.017931</td>\n","      <td>-0.167035</td>\n","      <td>-0.136833</td>\n","      <td>0.892118</td>\n","      <td>0.553089</td>\n","      <td>0.090010</td>\n","      <td>20.00</td>\n","      <td>0</td>\n","      <td>-0.273268</td>\n","      <td>-0.874175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 33 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-726fdddf-04f8-4c06-89e6-21da2160011e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-726fdddf-04f8-4c06-89e6-21da2160011e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-726fdddf-04f8-4c06-89e6-21da2160011e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["#concatenating newly created columns with original df\n","df = pd.concat([df, scaled_amount.rename('scaled_amount'), scaled_time.rename('scaled_time')], axis=1)\n","df.sample(5)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"VFPs3mFrItqW","outputId":"8d1ad006-bb13-4ab1-849a-4936c23c8735","executionInfo":{"status":"ok","timestamp":1668052083984,"user_tz":-330,"elapsed":5,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["              V1        V2        V3        V4        V5        V6        V7  \\\n","36609   1.359946 -0.472391  0.193190 -0.627921 -0.915409 -1.149255 -0.282488   \n","59276   1.234251 -1.629284  1.142892 -1.275278 -1.817738  0.896926 -1.814132   \n","105608 -0.607864  0.844533  2.159999  0.583729 -0.376256  0.196455  0.088164   \n","250552  1.924620 -0.161890 -0.276388  1.592308 -0.440760 -0.297931 -0.264486   \n","258671  2.059018  0.103878 -1.840409  0.211112  0.667313 -0.335666  0.080453   \n","\n","              V8        V9       V10  ...       V22       V23       V24  \\\n","36609  -0.328866 -0.984308  0.624930  ...  0.577036 -0.150528  0.450063   \n","59276   0.477853 -1.194435  1.332987  ...  0.135471  0.083290 -0.316635   \n","105608  0.164462  0.037933 -0.258902  ...  0.618793 -0.108433  0.068465   \n","250552  0.003940  1.217738 -0.009571  ... -1.206688  0.448110 -0.105388   \n","258671 -0.070007  0.247166 -0.211348  ... -0.895335  0.279072  0.102075   \n","\n","             V25       V26       V27       V28  Class  scaled_amount  \\\n","36609   0.637342 -0.122482 -0.008900  0.017812      0      -0.170317   \n","59276   0.028507 -0.155510  0.095224  0.021844      0      -0.120541   \n","105608 -0.190856 -0.397645 -0.164220  0.048876      0      -0.265271   \n","250552 -0.343233 -1.101249  0.056162 -0.031264      0      -0.321645   \n","258671 -0.234283  0.177579 -0.066446 -0.044309      0      -0.346073   \n","\n","        scaled_time  \n","36609     -1.183389  \n","59276     -0.969546  \n","105608    -0.530699  \n","250552     1.266700  \n","258671     1.346615  \n","\n","[5 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-fbde01d2-0ce6-4d5d-afb0-8f8349023d57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Class</th>\n","      <th>scaled_amount</th>\n","      <th>scaled_time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>36609</th>\n","      <td>1.359946</td>\n","      <td>-0.472391</td>\n","      <td>0.193190</td>\n","      <td>-0.627921</td>\n","      <td>-0.915409</td>\n","      <td>-1.149255</td>\n","      <td>-0.282488</td>\n","      <td>-0.328866</td>\n","      <td>-0.984308</td>\n","      <td>0.624930</td>\n","      <td>...</td>\n","      <td>0.577036</td>\n","      <td>-0.150528</td>\n","      <td>0.450063</td>\n","      <td>0.637342</td>\n","      <td>-0.122482</td>\n","      <td>-0.008900</td>\n","      <td>0.017812</td>\n","      <td>0</td>\n","      <td>-0.170317</td>\n","      <td>-1.183389</td>\n","    </tr>\n","    <tr>\n","      <th>59276</th>\n","      <td>1.234251</td>\n","      <td>-1.629284</td>\n","      <td>1.142892</td>\n","      <td>-1.275278</td>\n","      <td>-1.817738</td>\n","      <td>0.896926</td>\n","      <td>-1.814132</td>\n","      <td>0.477853</td>\n","      <td>-1.194435</td>\n","      <td>1.332987</td>\n","      <td>...</td>\n","      <td>0.135471</td>\n","      <td>0.083290</td>\n","      <td>-0.316635</td>\n","      <td>0.028507</td>\n","      <td>-0.155510</td>\n","      <td>0.095224</td>\n","      <td>0.021844</td>\n","      <td>0</td>\n","      <td>-0.120541</td>\n","      <td>-0.969546</td>\n","    </tr>\n","    <tr>\n","      <th>105608</th>\n","      <td>-0.607864</td>\n","      <td>0.844533</td>\n","      <td>2.159999</td>\n","      <td>0.583729</td>\n","      <td>-0.376256</td>\n","      <td>0.196455</td>\n","      <td>0.088164</td>\n","      <td>0.164462</td>\n","      <td>0.037933</td>\n","      <td>-0.258902</td>\n","      <td>...</td>\n","      <td>0.618793</td>\n","      <td>-0.108433</td>\n","      <td>0.068465</td>\n","      <td>-0.190856</td>\n","      <td>-0.397645</td>\n","      <td>-0.164220</td>\n","      <td>0.048876</td>\n","      <td>0</td>\n","      <td>-0.265271</td>\n","      <td>-0.530699</td>\n","    </tr>\n","    <tr>\n","      <th>250552</th>\n","      <td>1.924620</td>\n","      <td>-0.161890</td>\n","      <td>-0.276388</td>\n","      <td>1.592308</td>\n","      <td>-0.440760</td>\n","      <td>-0.297931</td>\n","      <td>-0.264486</td>\n","      <td>0.003940</td>\n","      <td>1.217738</td>\n","      <td>-0.009571</td>\n","      <td>...</td>\n","      <td>-1.206688</td>\n","      <td>0.448110</td>\n","      <td>-0.105388</td>\n","      <td>-0.343233</td>\n","      <td>-1.101249</td>\n","      <td>0.056162</td>\n","      <td>-0.031264</td>\n","      <td>0</td>\n","      <td>-0.321645</td>\n","      <td>1.266700</td>\n","    </tr>\n","    <tr>\n","      <th>258671</th>\n","      <td>2.059018</td>\n","      <td>0.103878</td>\n","      <td>-1.840409</td>\n","      <td>0.211112</td>\n","      <td>0.667313</td>\n","      <td>-0.335666</td>\n","      <td>0.080453</td>\n","      <td>-0.070007</td>\n","      <td>0.247166</td>\n","      <td>-0.211348</td>\n","      <td>...</td>\n","      <td>-0.895335</td>\n","      <td>0.279072</td>\n","      <td>0.102075</td>\n","      <td>-0.234283</td>\n","      <td>0.177579</td>\n","      <td>-0.066446</td>\n","      <td>-0.044309</td>\n","      <td>0</td>\n","      <td>-0.346073</td>\n","      <td>1.346615</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbde01d2-0ce6-4d5d-afb0-8f8349023d57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fbde01d2-0ce6-4d5d-afb0-8f8349023d57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fbde01d2-0ce6-4d5d-afb0-8f8349023d57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["# Removed the unnecessary columns Time and Amount from the data\n","df.drop(columns= ['Time', 'Amount'], axis = 1, inplace = True)\n","df.sample(5)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"fh7pINdEffGg","executionInfo":{"status":"ok","timestamp":1668052088780,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","df_feature = df.drop(['Class'], axis=1)\n","df_class = df['Class']\n","\n","train_feature, test_feature, train_class, test_class = train_test_split(df_feature, df_class, test_size=0.25, random_state = 11)"]},{"cell_type":"markdown","metadata":{"id":"MtVp9ztnKG0w"},"source":["# Deep Neural Network Model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"m9qwykl_G6en","executionInfo":{"status":"ok","timestamp":1668052096551,"user_tz":-330,"elapsed":2176,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import Dense, Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWYUaIBzG6iI","outputId":"41cddc4d-f5e1-4238-ff18-461684484af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","6676/6676 [==============================] - 22s 3ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0040 - val_accuracy: 0.9993\n","Epoch 2/20\n","6676/6676 [==============================] - 21s 3ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9993\n","Epoch 3/20\n","6676/6676 [==============================] - 25s 4ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9993\n","Epoch 4/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9993\n","Epoch 5/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9992\n","Epoch 6/20\n","6676/6676 [==============================] - 21s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9995\n","Epoch 7/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9994\n","Epoch 8/20\n","6676/6676 [==============================] - 25s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9995\n","Epoch 9/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9994\n","Epoch 10/20\n","6676/6676 [==============================] - 22s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9995\n","Epoch 11/20\n","6676/6676 [==============================] - 21s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9994\n","Epoch 12/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9993\n","Epoch 13/20\n","6676/6676 [==============================] - 22s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0047 - val_accuracy: 0.9992\n","Epoch 14/20\n","6676/6676 [==============================] - 24s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9993\n","Epoch 15/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9994\n","Epoch 16/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 0.9994\n","Epoch 17/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 0.9994\n","Epoch 18/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9994\n","Epoch 19/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0045 - val_accuracy: 0.9994\n","Epoch 20/20\n","6676/6676 [==============================] - 23s 3ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9995\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fd7dc103690>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# General architecture\n","model = Sequential()\n","model.add(Dense(32,activation ='relu', input_dim=30))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(train_feature, train_class, batch_size=32, epochs=20, validation_data=(test_feature, test_class))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubUbzGsAmsRT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6lMEATm_Mqn3"},"source":["# HyperParameter Tunning\n","\n","1) How to select appropriate optimizer\n","\n","2) No. of nodes in a layers\n","\n","3) How to select no. of layers\n","\n","4) All in all one model"]},{"cell_type":"markdown","metadata":{"id":"-y3SS4vWN4xS"},"source":["# KerasTuner\n","KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search. Easily configure your search space with a define-by-run syntax, then leverage one of the available search algorithms to find the best hyperparameter values for your models. KerasTuner comes with Bayesian Optimization, Hyperband, and Random Search algorithms built-in, and is also designed to be easy for researchers to extend in order to experiment with new search algorithms."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IRkkkRRG6rn","outputId":"2d086754-ac7f-4aa9-c635-db9e2b98d4f9","executionInfo":{"status":"ok","timestamp":1668052112134,"user_tz":-330,"elapsed":7097,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n","\u001b[K     |████████████████████████████████| 135 kB 32.1 MB/s \n","\u001b[?25hCollecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 47.8 MB/s \n","\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.38.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.50.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n","Installing collected packages: jedi, kt-legacy, keras-tuner\n","Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"]}],"source":["!pip install -U keras-tuner"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTIfW0SNOR6k","outputId":"344af3ed-81aa-418c-b4dd-34021b79731a","executionInfo":{"status":"ok","timestamp":1668052211252,"user_tz":-330,"elapsed":1656,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}],"source":["import kerastuner as kt"]},{"cell_type":"markdown","metadata":{"id":"LADY5LunUKQR"},"source":["# Apply all hyperparameter with one code (end-to-end)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"A1kVftcROSY3","executionInfo":{"status":"ok","timestamp":1668052224763,"user_tz":-330,"elapsed":569,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["def build_model(hp):\n","  model = Sequential()\n","  counter = 0\n","\n","  for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n","    if counter ==0:\n","      model.add(Dense(hp.Int('units' + str(i), min_value=8, max_value=128),\n","                      activation = hp.Choice('activation' + str(i), \n","                                            values = ['relu','sigmoid','tanh','elu',\n","                                                      'leaky_relu','softmax']), input_dim=30))\n","      ##model.add(Dropout(hp.Choice('dropout' + str(i), values= [0.1,0.2,0.3,0.4,0.5,0.6,0.7])))\n","    else :\n","      model.add(Dense(hp.Int('units' + str(i), min_value= 8, max_value =128),\n","                      activation = hp.Choice('activation' + str(i), \n","                                             values = ['relu','sigmoid','tanh','elu',\n","                                                      'leaky_relu','softmax'])))\n","      model.add(Dropout(hp.Choice('dropout' + str(i), values= [0.1,0.2])))\n","    counter +=1\n","  model.add(Dense(1, activation='sigmoid'))\n","  model.compile(optimizer = hp.Choice('optimizer', values =['adam','rmsprop','sgd',\n","                                                            'nadam','adadelta','adagrad']),\n","                loss = 'binary_crossentropy', metrics =['accuracy'])\n","  \n","  return model\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ooueiTHVXEa5","executionInfo":{"status":"ok","timestamp":1668052233727,"user_tz":-330,"elapsed":3235,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["# Best optimizer\n","tuner = kt.RandomSearch(build_model, objective ='val_accuracy', \n","                        max_trials=5, directory = \"MyDir\", project_name = 'final_model')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvizbzWsY49E","outputId":"4f506ce2-fa2d-472d-8954-c347338c4adb","executionInfo":{"status":"ok","timestamp":1668053365789,"user_tz":-330,"elapsed":1036176,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 03m 23s]\n","val_accuracy: 0.9982023239135742\n","\n","Best val_accuracy So Far: 0.9993398785591125\n","Total elapsed time: 00h 18m 39s\n"]}],"source":["tuner.search(train_feature, train_class, batch_size=32, epochs=6, validation_data=(test_feature, test_class))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"LjeSknDRY5An","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668053395075,"user_tz":-330,"elapsed":626,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}},"outputId":"0ec67218-37cf-4c7f-ec29-cb0d637510d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'num_layers': 3,\n"," 'units0': 112,\n"," 'activation0': 'sigmoid',\n"," 'optimizer': 'rmsprop',\n"," 'units1': 8,\n"," 'activation1': 'relu',\n"," 'dropout1': 0.1,\n"," 'units2': 8,\n"," 'activation2': 'relu',\n"," 'dropout2': 0.1}"]},"metadata":{},"execution_count":18}],"source":["tuner.get_best_hyperparameters()[0].values"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"PG5w5AhzdWdf","executionInfo":{"status":"ok","timestamp":1668053417490,"user_tz":-330,"elapsed":753,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["best_model = tuner.get_best_models()[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgWu95S3dZ79","outputId":"25603677-0349-46f0-f6c3-092d514730d5","executionInfo":{"status":"ok","timestamp":1668053423431,"user_tz":-330,"elapsed":720,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.engine.sequential.Sequential at 0x7ff738610b90>"]},"metadata":{},"execution_count":20}],"source":["best_model"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"8MH4p54rY5Du","executionInfo":{"status":"ok","timestamp":1668053436631,"user_tz":-330,"elapsed":862,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["model = tuner.get_best_models(num_models=1)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XssW_hHncrjb","outputId":"219639e8-dc0a-42d1-bfcf-900f90a3b02a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 96)                864       \n","                                                                 \n"," dropout (Dropout)           (None, 96)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 94)                9118      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 94)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 81)                7695      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 81)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 108)               8856      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 108)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 109       \n","                                                                 \n","=================================================================\n","Total params: 26,642\n","Trainable params: 26,642\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"1O8Ikf6jY5Ga","executionInfo":{"status":"ok","timestamp":1668056323309,"user_tz":-330,"elapsed":621,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["def build_model(hp):\n","  model1 = Sequential()\n","  counter = 0\n","\n","  for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n","    if counter ==0:\n","      model1.add(Dense(hp.Int('units' + str(i), min_value=8, max_value=128),\n","                      activation = hp.Choice('activation' + str(i), \n","                                            values = ['relu','sigmoid','tanh','elu',\n","                                                      'leaky_relu','softmax']), input_dim=30))\n","      ##model.add(Dropout(hp.Choice('dropout' + str(i), values= [0.1,0.2,0.3,0.4,0.5,0.6,0.7])))\n","    else :\n","      model1.add(Dense(hp.Int('units' + str(i), min_value= 8, max_value =128),\n","                      activation = hp.Choice('activation' + str(i), \n","                                             values = ['relu','sigmoid','tanh','elu',\n","                                                      'leaky_relu','softmax'])))\n","      model1.add(Dropout(hp.Choice('dropout' + str(i), values= [0.1,0.2])))\n","    counter +=1\n","  model1.add(Dense(1, activation='sigmoid'))\n","  model1.compile(optimizer = hp.Choice('optimizer', values =['adam','rmsprop','sgd',\n","                                                            'nadam','adadelta','adagrad']),\n","                loss = 'binary_crossentropy', metrics=[tf.keras.metrics.Recall(thresholds=0)])\n","  \n","  return model1\n","    "]},{"cell_type":"code","execution_count":28,"metadata":{"id":"QpnelNS3cLDa","executionInfo":{"status":"ok","timestamp":1668056327893,"user_tz":-330,"elapsed":1123,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}}},"outputs":[],"source":["# Best optimizer\n","tuner1 = kt.RandomSearch(build_model, \n","                        max_trials=5, directory = \"MyDir\", project_name = 'final_model_recall')"]},{"cell_type":"code","source":["tuner1.search(train_feature, train_class, batch_size=32, epochs=20, validation_data=(test_feature, test_class))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"BUzOMqvJ3Vn5","executionInfo":{"status":"error","timestamp":1668056378444,"user_tz":-330,"elapsed":47323,"user":{"displayName":"Ankush Yadav","userId":"12403664802487336291"}},"outputId":"fb0f9452-f8be-428a-be16-d050f46b4e52"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Search: Running Trial #1\n","\n","Value             |Best Value So Far |Hyperparameter\n","3                 |?                 |num_layers\n","66                |?                 |units0\n","leaky_relu        |?                 |activation0\n","adam              |?                 |optimizer\n","\n","Epoch 1/20\n","6676/6676 [==============================] - 35s 5ms/step - loss: 0.0102 - recall: 1.0000 - val_loss: 0.0048 - val_recall: 1.0000\n","Epoch 2/20\n","3061/6676 [============>.................] - ETA: 13s - loss: 0.0038 - recall: 1.0000"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-ad3013583b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["tuner1.get_best_hyperparameters()[0].values"],"metadata":{"id":"Jixt1bC23imD"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}